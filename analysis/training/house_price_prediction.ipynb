{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.lightgbm\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing # ONLY TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/jgomacor/projects/Dream_Team_2024/analysis/training/mlruns/993656704908748596', creation_time=1731771951114, experiment_id='993656704908748596', last_update_time=1731771951114, lifecycle_stage='active', name='house_price_prediction', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"house_price_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"Load and preprocess the dataset\"\"\"\n",
    "    # df = pd.read_csv(data_path)\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "\n",
    "    # Assuming your target variable is named 'price'\n",
    "    # X = df.drop('Listing.Price.ClosePrice', axis=1)\n",
    "    # y = df['Listing.Price.ClosePrice']\n",
    "\n",
    "    \n",
    "    X = df.drop('MedHouseVal', axis=1)\n",
    "    y = df['MedHouseVal']\n",
    "    \n",
    "    # Handle categorical variables (if any)\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluation metrics function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Calculate regression metrics\"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"mse\": mse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for sklearn Random Forest\n",
    "def train_sklearn_rf(X_train, X_test, y_train, y_test, params):\n",
    "    with mlflow.start_run(run_name=\"sklearn_rf\"):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate and log metrics\n",
    "        metrics = evaluate_model(rf, X_test, y_test)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(rf, \"model\")\n",
    "        \n",
    "        return rf, metrics\n",
    "\n",
    "# Training function for LightGBM\n",
    "def train_lightgbm(X_train, X_test, y_train, y_test, params):\n",
    "    with mlflow.start_run(run_name=\"lightgbm\"):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        lgb = LGBMRegressor(**params)\n",
    "        lgb.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate and log metrics\n",
    "        metrics = evaluate_model(lgb, X_test, y_test)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.lightgbm.log_model(lgb, \"model\")\n",
    "        \n",
    "        return lgb, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/16 17:39:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Metrics: {'rmse': np.float64(0.4630272361128509), 'mse': np.float64(0.2143942213823058), 'mae': np.float64(0.308491698784304), 'r2': 0.8363913671668293}\n"
     ]
    }
   ],
   "source": [
    "# Example usage in notebook cells:\n",
    "# Cell 1: Load data\n",
    "X_train, X_test, y_train, y_test = load_data('df_train.csv')\n",
    "\n",
    "# Cell 2: Define parameters for each model\n",
    "sklearn_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# # Cell 3: Train sklearn Random Forest\n",
    "# sklearn_model, sklearn_metrics = train_sklearn_rf(\n",
    "#     X_train, X_test, y_train, y_test, sklearn_params\n",
    "# )\n",
    "# print(\"Sklearn RF Metrics:\", sklearn_metrics)\n",
    "\n",
    "# Cell 4: Train LightGBM\n",
    "lightgbm_model, lightgbm_metrics = train_lightgbm(\n",
    "    X_train, X_test, y_train, y_test, lightgbm_params\n",
    ")\n",
    "print(\"LightGBM Metrics:\", lightgbm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/16 17:41:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in house_price_models with timestamp 20241116_174128\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model(model, scaler=None, metrics=None, model_dir='models'):\n",
    "    \"\"\"\n",
    "    Save the LightGBM model, scaler, and metrics using joblib\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : LGBMRegressor\n",
    "        Trained LightGBM model\n",
    "    scaler : StandardScaler, optional\n",
    "        Fitted scaler used for preprocessing\n",
    "    metrics : dict, optional\n",
    "        Model performance metrics\n",
    "    model_dir : str\n",
    "        Directory to save the model files\n",
    "    \"\"\"\n",
    "    # Create timestamp for versioning\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create model directory if it doesn't exist\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(model_dir, f'lightgbm_model_{timestamp}.joblib')\n",
    "    dump(model, model_path)\n",
    "    \n",
    "    # Save scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler_path = os.path.join(model_dir, f'scaler_{timestamp}.joblib')\n",
    "        dump(scaler, scaler_path)\n",
    "    \n",
    "    # Save metrics if provided\n",
    "    if metrics is not None:\n",
    "        metrics_path = os.path.join(model_dir, f'metrics_{timestamp}.joblib')\n",
    "        dump(metrics, metrics_path)\n",
    "    \n",
    "    print(f\"Model saved in {model_dir} with timestamp {timestamp}\")\n",
    "    return timestamp\n",
    "\n",
    "def load_saved_model(timestamp, model_dir='models'):\n",
    "    \"\"\"\n",
    "    Load the saved model, scaler, and metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    timestamp : str\n",
    "        Timestamp of the saved model version\n",
    "    model_dir : str\n",
    "        Directory where model files are saved\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (model, scaler, metrics)\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(model_dir, f'lightgbm_model_{timestamp}.joblib')\n",
    "    model = load(model_path)\n",
    "    \n",
    "    # Try to load scaler if it exists\n",
    "    scaler = None\n",
    "    scaler_path = os.path.join(model_dir, f'scaler_{timestamp}.joblib')\n",
    "    if os.path.exists(scaler_path):\n",
    "        scaler = load(scaler_path)\n",
    "    \n",
    "    # Try to load metrics if they exist\n",
    "    metrics = None\n",
    "    metrics_path = os.path.join(model_dir, f'metrics_{timestamp}.joblib')\n",
    "    if os.path.exists(metrics_path):\n",
    "        metrics = load(metrics_path)\n",
    "    \n",
    "    return model, scaler, metrics\n",
    "\n",
    "# Example usage in notebook cells:\n",
    "\n",
    "# Cell 1: Train model (using code from previous artifact)\n",
    "lightgbm_model, lightgbm_metrics = train_lightgbm(\n",
    "    X_train, X_test, y_train, y_test, lightgbm_params\n",
    ")\n",
    "\n",
    "# Cell 2: Save the model\n",
    "timestamp = save_model(\n",
    "    model=lightgbm_model,\n",
    "    metrics=lightgbm_metrics,\n",
    "    model_dir='house_price_models'\n",
    ")\n",
    "\n",
    "# Cell 3: Later, when you need to load the model\n",
    "loaded_model, loaded_scaler, loaded_metrics = load_saved_model(\n",
    "    timestamp,\n",
    "    model_dir='house_price_models'\n",
    ")\n",
    "\n",
    "# Cell 4: Make predictions with loaded model\n",
    "def predict_price(X_new, model, scaler=None):\n",
    "    \"\"\"\n",
    "    Make predictions using the loaded model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_new : pd.DataFrame\n",
    "        New data to predict on\n",
    "    model : LGBMRegressor\n",
    "        Loaded model\n",
    "    scaler : StandardScaler, optional\n",
    "        Loaded scaler if used in training\n",
    "    \"\"\"\n",
    "    if scaler is not None:\n",
    "        X_new = scaler.transform(X_new)\n",
    "    \n",
    "    predictions = model.predict(X_new)\n",
    "    return predictions\n",
    "\n",
    "# Example prediction\n",
    "# new_data = pd.DataFrame(...)  # Your new data\n",
    "# predictions = predict_price(new_data, loaded_model, loaded_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in production_models with timestamp 20241116_174133\n"
     ]
    }
   ],
   "source": [
    "timestamp = save_model(\n",
    "    model=lightgbm_model,\n",
    "    metrics=lightgbm_metrics,\n",
    "    model_dir='production_models'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
