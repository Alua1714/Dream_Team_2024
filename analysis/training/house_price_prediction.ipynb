{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.lightgbm\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing # ONLY TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/jgomacor/projects/Dream_Team_2024/analysis/training/mlruns/993656704908748596', creation_time=1731771951114, experiment_id='993656704908748596', last_update_time=1731771951114, lifecycle_stage='active', name='house_price_prediction', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"house_price_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"Load and preprocess the dataset\"\"\"\n",
    "    # df = pd.read_csv(data_path)\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "\n",
    "    # Assuming your target variable is named 'price'\n",
    "    # X = df.drop('Listing.Price.ClosePrice', axis=1)\n",
    "    # y = df['Listing.Price.ClosePrice']\n",
    "\n",
    "    \n",
    "    X = df.drop('MedHouseVal', axis=1)\n",
    "    y = df['MedHouseVal']\n",
    "    \n",
    "    # Handle categorical variables (if any)\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluation metrics function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Calculate regression metrics\"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"mse\": mse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for sklearn Random Forest\n",
    "def train_sklearn_rf(X_train, X_test, y_train, y_test, params):\n",
    "    with mlflow.start_run(run_name=\"sklearn_rf\"):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate and log metrics\n",
    "        metrics = evaluate_model(rf, X_test, y_test)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(rf, \"model\")\n",
    "        \n",
    "        return rf, metrics\n",
    "\n",
    "# Training function for LightGBM\n",
    "def train_lightgbm(X_train, X_test, y_train, y_test, params):\n",
    "    with mlflow.start_run(run_name=\"lightgbm\"):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        lgb = LGBMRegressor(**params)\n",
    "        lgb.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate and log metrics\n",
    "        metrics = evaluate_model(lgb, X_test, y_test)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.lightgbm.log_model(lgb, \"model\")\n",
    "        \n",
    "        return lgb, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/16 17:39:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Metrics: {'rmse': np.float64(0.4630272361128509), 'mse': np.float64(0.2143942213823058), 'mae': np.float64(0.308491698784304), 'r2': 0.8363913671668293}\n"
     ]
    }
   ],
   "source": [
    "# Example usage in notebook cells:\n",
    "# Cell 1: Load data\n",
    "X_train, X_test, y_train, y_test = load_data('df_train.csv')\n",
    "\n",
    "# Cell 2: Define parameters for each model\n",
    "sklearn_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# # Cell 3: Train sklearn Random Forest\n",
    "# sklearn_model, sklearn_metrics = train_sklearn_rf(\n",
    "#     X_train, X_test, y_train, y_test, sklearn_params\n",
    "# )\n",
    "# print(\"Sklearn RF Metrics:\", sklearn_metrics)\n",
    "\n",
    "# Cell 4: Train LightGBM\n",
    "lightgbm_model, lightgbm_metrics = train_lightgbm(\n",
    "    X_train, X_test, y_train, y_test, lightgbm_params\n",
    ")\n",
    "print(\"LightGBM Metrics:\", lightgbm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1838\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 2.071947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/16 17:44:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in house_price_models with timestamp 20241116_174445\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=<pandas.core.indexing._iLocIndexer object at 0x7a44075c8220>.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 118\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Example prediction\u001b[39;00m\n\u001b[1;32m    117\u001b[0m new_data \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc  \u001b[38;5;66;03m# Your new data\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_scaler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 113\u001b[0m, in \u001b[0;36mpredict_price\u001b[0;34m(X_new, model, scaler)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_new)\n\u001b[0;32m--> 113\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/projects/Dream_Team_2024/venv/lib/python3.10/site-packages/lightgbm/sklearn.py:1007\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator not fitted, call fit before exploiting the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[0;32m-> 1007\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43m_LGBMCheckArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m!=\u001b[39m n_features:\n",
      "File \u001b[0;32m~/projects/Dream_Team_2024/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1027\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1027\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1028\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1029\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1030\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1032\u001b[0m         )\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;66;03m# If input is a Series-like object (eg. pandas Series or polars Series)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=<pandas.core.indexing._iLocIndexer object at 0x7a44075c8220>.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model(model, scaler=None, metrics=None, model_dir='models'):\n",
    "    \"\"\"\n",
    "    Save the LightGBM model, scaler, and metrics using joblib\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : LGBMRegressor\n",
    "        Trained LightGBM model\n",
    "    scaler : StandardScaler, optional\n",
    "        Fitted scaler used for preprocessing\n",
    "    metrics : dict, optional\n",
    "        Model performance metrics\n",
    "    model_dir : str\n",
    "        Directory to save the model files\n",
    "    \"\"\"\n",
    "    # Create timestamp for versioning\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create model directory if it doesn't exist\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(model_dir, f'lightgbm_model_{timestamp}.joblib')\n",
    "    dump(model, model_path)\n",
    "    \n",
    "    # Save scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler_path = os.path.join(model_dir, f'scaler_{timestamp}.joblib')\n",
    "        dump(scaler, scaler_path)\n",
    "    \n",
    "    # Save metrics if provided\n",
    "    if metrics is not None:\n",
    "        metrics_path = os.path.join(model_dir, f'metrics_{timestamp}.joblib')\n",
    "        dump(metrics, metrics_path)\n",
    "    \n",
    "    print(f\"Model saved in {model_dir} with timestamp {timestamp}\")\n",
    "    return timestamp\n",
    "\n",
    "def load_saved_model(timestamp, model_dir='models'):\n",
    "    \"\"\"\n",
    "    Load the saved model, scaler, and metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    timestamp : str\n",
    "        Timestamp of the saved model version\n",
    "    model_dir : str\n",
    "        Directory where model files are saved\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (model, scaler, metrics)\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(model_dir, f'lightgbm_model_{timestamp}.joblib')\n",
    "    model = load(model_path)\n",
    "    \n",
    "    # Try to load scaler if it exists\n",
    "    scaler = None\n",
    "    scaler_path = os.path.join(model_dir, f'scaler_{timestamp}.joblib')\n",
    "    if os.path.exists(scaler_path):\n",
    "        scaler = load(scaler_path)\n",
    "    \n",
    "    # Try to load metrics if they exist\n",
    "    metrics = None\n",
    "    metrics_path = os.path.join(model_dir, f'metrics_{timestamp}.joblib')\n",
    "    if os.path.exists(metrics_path):\n",
    "        metrics = load(metrics_path)\n",
    "    \n",
    "    return model, scaler, metrics\n",
    "\n",
    "# Example usage in notebook cells:\n",
    "\n",
    "# Cell 1: Train model (using code from previous artifact)\n",
    "lightgbm_model, lightgbm_metrics = train_lightgbm(\n",
    "    X_train, X_test, y_train, y_test, lightgbm_params\n",
    ")\n",
    "\n",
    "# Cell 2: Save the model\n",
    "timestamp = save_model(\n",
    "    model=lightgbm_model,\n",
    "    metrics=lightgbm_metrics,\n",
    "    model_dir='house_price_models'\n",
    ")\n",
    "\n",
    "# Cell 3: Later, when you need to load the model\n",
    "loaded_model, loaded_scaler, loaded_metrics = load_saved_model(\n",
    "    timestamp,\n",
    "    model_dir='house_price_models'\n",
    ")\n",
    "\n",
    "# Cell 4: Make predictions with loaded model\n",
    "def predict_price(X_new, model, scaler=None):\n",
    "    \"\"\"\n",
    "    Make predictions using the loaded model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_new : pd.DataFrame\n",
    "        New data to predict on\n",
    "    model : LGBMRegressor\n",
    "        Loaded model\n",
    "    scaler : StandardScaler, optional\n",
    "        Loaded scaler if used in training\n",
    "    \"\"\"\n",
    "    if scaler is not None:\n",
    "        X_new = scaler.transform(X_new)\n",
    "    \n",
    "    predictions = model.predict(X_new)\n",
    "    return predictions\n",
    "\n",
    "# Example prediction\n",
    "new_data = X_train.iloc[0:1]  # Your new data\n",
    "predictions = predict_price(new_data, loaded_model, loaded_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in production_models with timestamp 20241116_174133\n"
     ]
    }
   ],
   "source": [
    "timestamp = save_model(\n",
    "    model=lightgbm_model,\n",
    "    metrics=lightgbm_metrics,\n",
    "    model_dir='production_models'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
